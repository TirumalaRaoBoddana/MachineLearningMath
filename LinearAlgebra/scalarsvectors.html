<!DOCTYPE html>
<html>
<head>
    <title>Scalars And Vectors</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <style>
        img{
            display: flex;
            align-items: center;
            justify-content: center;
            max-width: 300px;
            height: auto;
        }
        .coderlogo{
            width:30px;
            height:30px;
            display: inline-block;
        }
        a:hover{
            text-decoration: none;
        }
        .navigation{
            display: flex;
            flex-direction: row-reverse;
            align-items: flex-start;
            justify-content: space-between;
            margin:0vh 10vw;
            margin-bottom:2vh;
        }
        .navigation div{
            padding:6px;
            border-radius: 20px;
            margin-top:1vh;
            width:100px;
            text-align:center;
           box-shadow: 3px 3px 3px 3px grey;
        }
    </style>
</head>
<body>
    <div class="container">
        <h4 class="font-weight-bold mb-4">Scalars and Vectors in Machine Learning</h4>
        <div>
            <h6>Welcome Back, Machine Learning Enthusiast! <img class="coderlogo" src="coder.png"></h6>
            <p class="mb-0">In this blog, we are mainly focusing on the fundamental concepts of scalars and vectors in machine learning. Scalars and vectors play a crucial role in various aspects of machine learning, from representing data to defining mathematical operations and building models. Understanding the concepts of scalars and vectors is essential for both beginners and advanced practitioners in the field of machine learning. Whether you are learning about feature representation, model parameters, or optimization techniques, a solid grasp of scalars and vectors will greatly enhance your understanding and proficiency in machine learning.</p>
        </div>
        <h3 class="mt-4">Scalars</h3>
        <p>A scalar is a single numerical value. It has magnitude but no direction. In machine learning,Scalars are the <b>0-rank Tensors</b>(doesn't have dimension),are often used to represent simple quantities such as the age of a person, the price of a product, or the temperature of a city. Scalars are typically denoted by lowercase letters, such as <b>a</b> or <b>b</b>.</p>
        <h3>Representation of Scalars: </h3>
        <img src="scalarsvectors\tensor.jpg" alt="Tensors in Machine Learning"class="img-fluid mx-auto">
        <h5>Python Code: </h5>
        <pre style="font-weight:bold">
            import numpy as np
            scalar_int=np.int16(20)
            print(scalar_int)
            print(type(scalar_int))
            scalar_float=np.float64(10)
            print(scalar_float)
            print(type(scalar_float))
        </pre>
        <h5 >Output: </h5>
        <pre style="font-weight:bold">
            20
            &lt class 'numpy.int16' &gt
            10.0
            &lt class 'numpy.float64' &gt
        </pre>
        <h5>Arithmetic Operation On Scalars: </h5>
        <pre style="font-weight:bold;">
            # Perform arithmetic operations on scalars
            addition = scalar1 + scalar2
            subtraction = scalar1 - scalar2
            multiplication = scalar1 * scalar2
            division = scalar1 / scalar2

            # Print results of arithmetic operations
            print("Addition:", addition)
            print("Subtraction:", subtraction)
            print("Multiplication:", multiplication)
            print("Division:", division)
        </pre>
        <h5 >Output: </h5>
        <pre style="font-weight:bold">
            Addition: 30.0
            Subtraction: 10.0
            Multiplication: 200.0
            Division: 2.0
        </pre>
        <p></p>
        <h2>Vectors</h2>
        <p>A vector is an ordered collection of scalar values. It has both magnitude and direction.Vectors are Considered as the Rank-1 Tensors Vectors are widely used in machine learning to represent features, inputs, outputs, parameters, and more. Common examples of vectors in machine learning include:</p>
        <ul>
            <li>Feature vectors: Representing data points in a feature space.</li>
            <li>Weight vectors: Representing the parameters of a model.</li>
            <li>Error vectors: Representing the differences between predicted and actual values.</li>
        </ul>
        <p>Vectors are typically denoted by bold lowercase letters or with an arrow on top, such as <strong>x&#772;</strong>, <strong>y&#772;</strong>.
            <br>For Example: a=[1,2,3,4,5],b=[1.3,3.4,8.9,90.98]
        </p>
        <h5>Repersentation Of Vectors: </h5>
        <img class="img-fluid mx-auto" src="scalarsvectors\vector.jpg" alt="Vector Representation">
        <p>In the context of Machine Learning, any type of input data is converted into vector format, a process known as vectorization. This transformation allows us to represent complex data structures, such as images, text, or audio, as numerical vectors. Once the data is in vector format, we can apply various mathematical operations and algorithms, including linear algebra, to analyze and draw useful insights from the data.</p>
        <img class="img-fluid mx-auto" src="scalarsvectors\vectors.jpg" alt="Vectorization">
        <h5>Python Code: </h5>
        <pre style="font-weight:bold">
            #vectors or 1-d arrays
            print("integer value vector")
            vector=np.array([i for i in range(1,6,1)])
            print("vector=",vector)
            print("vector shape=",vector.shape)
            print("vector size=",vector.size)
            print("vector datatype=",vector.dtype)
            print("vector dimension=",vector.ndim)
            print("floating value vector: ")
            vector_float=np.array(vector,dtype="float32")#with dype we can specify the data type
            print("vector=",vector_float)
            print("vector shape=",vector_float.shape)
            print("vector size=",vector_float.size)
            print("vector datatype=",vector_float.dtype)
            print("vector dimension=",vector_float.ndim)
        </pre>
        <h5>Output</h5>
        <pre style="font-weight:bold">
            integer value vector
            vector= [1 2 3 4 5]
            vector shape= (5,)
            vector size= 5
            vector datatype= int32
            vector dimension= 1
            floating value vector: 
            vector= [1. 2. 3. 4. 5.]
            vector shape= (5,)
            vector size= 5
            vector datatype= float32
            vector dimension= 1
        </pre>
        <h3>Operations on Vectors</h3>
        <p>In machine learning, various mathematical operations are performed on scalars and vectors. Some common operations include addition, subtraction, multiplication, and division. For vectors, additional operations such as dot product, cross product, and vector norms are also essential.</p>
        <p>
            vector1=[6,7,8,9]<br>
            vector2=[1,2,3,4]<br>
            vector1+vector2=[6+1,7+2,8+3,9+4]=[7,9,11,13]<br>
            vector1-vector2=[6-1,7-2,8-3,9-4]=[5,5,5,5]<br>
        </p>
        <h5>Python Code: </h5>
        <pre style="font-weight:bold;">
            #vector operations
            a=np.array([6,7,8,9])
            b=np.array([1,2,3,4])
            addition=a+b
            sub=a-b
            print("addition of the vectors: ",addition)
            print("subtraction of the vectors: ",sub)
            #if the shape of two vectors are not same then it will generate Error
            a=np.array([6,7,8,9,10])
            b=np.array([1,2,3,4])
            print("vector a: ",a)
            print("vector b: ",b)
            print("shape of a: ",a.shape)#for addition or subtraction the the shape of the vectors shold be same
            print("shape of b: ",b.shape)
            addition=a+b
            sub=a-b
            print("addition of the vectors: ",addition)
            print("subtraction of the vectors: ",sub)
        </pre>
        <h5>Output: </h5>
        <pre style="font-weight:bold">
            vector a:  [6 7 8 9]
            vector b:  [1 2 3 4]
            shape of a:  (4,)
            shape of b:  (4,)
            addition of the vectors:  [ 7  9 11 13]
            subtraction of the vectors:  [5 5 5 5]
            vector a:  [ 6  7  8  9 10]
            vector b:  [1 2 3 4]
            shape of a:  (5,)
            shape of b:  (4,)
            <label style="color:red;">ValueError: operands could not be broadcast together with shapes (5,) (4,)</label> 
        </pre>
        <h5>Intuition Behind Vector Operations: </h5>
        <h5>Vector Addition:</h5>
        <p>
            Let's think of vectors as arrows in space. Each vector has a direction and a magnitude (length).When you add two vectors together, you're essentially placing the tail of the second vector at the head of the first vector, and the resultant vector (the sum) is the arrow that goes from the tail of the first vector to the head of the second vector.
            <br>Consider A Vector a=[3 , 4] and b=[10 , 2]<br> when adding two vectors, you add the x components together to get the x component of the resultant vector, and similarly, you add the y components together to get the y component of the resultant vector.
        </p>
        <img src="scalarsvectors\vectoraddition.png" alt="Vector Addition" class="img-fluid mx-auto">
        <h5>Vector Subtraction:</h5>
        <p>
            To subtract vector B from vector A, you essentially reverse the direction of vector B and then add it to vector A. Mathematically, this is done by negating the components of vector B and then adding them to the components of vector A
           <br>Consider A Vector a=[3 , 4] and b=[10 , 2]<br>
           a−b=a+(-b) <br>
           resultant vector=[3-10,4-2]=[-7,2]
        </p>
        <h5>Scaling: </h5>
        <p>
            Vector scaling in linear algebra, especially in the context of machine learning, often involves multiplying a vector by a scalar value. This operation resizes the vector but doesn't change its direction.<br>
            Given a vector v=[v1,v2,v3,....vn] and a scalar c the scaling operation results in a new vector cv,where eeach component of the original vector is multiplied by the scalar:<br>
            cv=[cv1,cv2,cv3,....cvn]
            <br>Here, c can be any real number.if c>1 the resulting vector will be longer than the original; if  0< c < 1 he resulting vector will be shorter (scaled down); and if c< 0 the resulting vector will also change direction (rotate 180 degrees) due to the negative scalar.
        </p>
        <div class="text-center">
            <figure class="figure mx-auto">
                <img src="scalarsvectors\scaling.png" alt="Vector Scaling" class="img-fluid mx-auto">
                <figcaption class="figure-caption">Vector Scaling by positive number</figcaption>
            </figure>
        </div>
        <div class="text-center">
            <figure class="figure mx-auto">
                <img src="scalarsvectors\scalingnegative.png" alt="Vector Scaling" class="img-fluid mx-auto">
                <figcaption class="figure-caption">Vector Scaling by Negative  number</figcaption>
              </figure>
        </div>
        <h5>Magnitude of the Vector(Norms)</h5>
        <p>
            In machine learning, the magnitude of a vector is a fundamental concept used in various contexts, such as feature scaling, regularization, and similarity calculations.<br><br>
            The magnitude of a vector <b>z</b> in machine learning is typically computed using the Euclidean norm (also known as the <b>L<sup>2</sup></b>norm), denoted as 
            <b>∥<b>z</b>∥<sub>2</sub></b> For a vector <b>z</b> with n components, the Euclidean norm is calculated as:
            <br>
            <b>||z||<sub>2</sub></b>= &#x221A;( <span>&#x1D63B;</span><sup>2</sup><sub>1</sub> + <span>&#x1D63B;</span><sup>2</sup><sub>2</sub> + &#x2026; + <span>&#x1D63B;</span><sup>2</sup><sub>n</sub> )
        </p>
        <h5 style="font-weight:bolder">Types of vector Norms: </h5>
        <ul>
            <li>
                <h5 style="font-weight:bold;">Euclidean Norm (L2 Norm):</h5>
                <p>
                    The Euclidean norm, also known as the <b>L<sup>2</sup></b> norm, is perhaps the most widely used norm. It is defined as the square root of the sum of the squares of the components of the vector.<br>
                    For a vector z=[z1,z2,z3,...zn],the Euclidean norm is calculated as:<br>
                    <b>||z||<sub>2</sub></b>= &#x221A;( <span>&#x1D63B;</span><sup>2</sup><sub>1</sub> + <span>&#x1D63B;</span><sup>2</sup><sub>2</sub> + &#x2026; + <span>&#x1D63B;</span><sup>2</sup><sub>n</sub> )<br>
                    This norm corresponds to the distance of the vector from the origin in Euclidean space and is commonly used in geometric contexts and machine learning algorithms.
                </p>
            </li>
            <li>
                <h5 style="font-weight:bold;">Taxicab Norm (L1 Norm):</h5>
                <p>
                    The Taxicab norm, also known as the <b>L<sup>1</sup></b>norm or Manhattan norm, is defined as the sum of the absolute values of the components of the vector.<br>
                    For a vector v=[v1,v2,v3,...vn],the Taxicab norm is calculated as:<br>
                    ||v||<sub>1</sub>=|v<sub>1</sub>|+|v<sub>2</sub>|+|v<sub>3</sub>|+...|v<sub>n</sub>|
                    This norm corresponds to the distance between two points in a grid-like path (like a taxicab traveling on city blocks), and it is often used in optimization problems and sparse signal processing.
                </p>
            </li>
            <li>
                <h5 style="font-weight:bold;">Maximum Norm (L∞ Norm):</h5>
                <p>
                    The Maximum norm, also known as the L<sup>∞</sup>norm or infinity norm, is defined as the maximum absolute value of the components of the vector. <br>
                    For a vector v=[v1,v2,v3,..,vn],the Maximum norm is calculated as:
                    <br>||v||<sub>∞</sub>=max(||v<sub>1</sub>||,||v<sub>2</sub>||,||v<sub>3</sub>||,....,||v<sub>n</sub>||)
                </p>
            </li>
            <li>
                <h5 style="font-weight:bold;">p-Norm:</h5>
                <p>
                    The p-norm is a generalization of the Euclidean norm and Taxicab norm. It is defined as the p-th root of the sum of the p-th powers of the absolute values of the components of the vector.<br>
                    For a vector v=[v1,v2,v3,...vn],the Taxicab norm is calculated as:<br>
                    ||v||<sub>p</sub>=(||v<sub>1</sub>||<sup>p</sup>+||v<sub>2</sub>||<sup>p</sup>+....+||v<sub>n</sub>||<sup>p</sup>)<sup>1/p</sup><br>
                    The Euclidean norm is a special case of the p-norm when p=2 and the Taxicab norm is a special case when p=1.The p-norm is useful for generalizing distance measures and solving optimization problems with different criteria.
                </p>
            </li>
        </ul>
        <h5>Python Code: </h5>
        <pre>
            import numpy as np
            list=[]
            n=int(input("Enter number of elements of the array: "))
            for i in range(n):
                list.append(float(input("Enter value: ")))
            arr=np.array(list,dtype=float)
            sum=0
            p=int(input("Enter p value: "))
            for i in arr:
                sum+=abs(i)**p
            print("p th norm of the given vector is: ",abs(sum)**(1/p))
        </pre>
        <h5>Output: </h5>
        <pre>
            Enter number of elements of the array:  4
            Enter value:  1
            Enter value:  2
            Enter value:  3
            Enter value:  4
            Enter p value:  2
            p th norm of the given vector is:  5.477225575051661
        </pre>
        <h5>
            Using numpy.linalg.norm(arr,ord=p): 
        </h5>
        <pre>
            import numpy as np
            print(np.linalg.norm(arr,2))
        </pre>
        <h5>Output: </h5>
        <pre>
            5.477225575051661
        </pre>
        <p>To calculate infinity norm:
        <pre>
        import numpy as np
        vector = np.array([1, -3, 2, 5, -4])
        print(np.linalg.norm(vector,ord=np.inf))    
        print("l infinity norm of the vector is: ",max(vector))
        </pre>
        <h5>Output: </h5>
        <pre>
        5.0
        5
        </pre>
        </p>
    </div>
    <div class="container">
        <h5>Resources: </h5>
        <a href="https://www.desmos.com/calculator/u8wt5rnw9n">Desmos(For Visualization of Vectors)</a><br>
        <a href="https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">3Blue1Brown(Linear Algebra Playlist)</a><br>
        <a href="https://www.khanacademy.org/math/linear-algebra">Khan Academy - Linear Algebra</a><br>
        <a href="https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/">Linear Algebra</a>
    </div>
    <div class="navigation">
        <div><a href="linearcombinations.html" style="font-size:1.25rem">Next &nbsp&nbsp<i class=" fa fa-solid fa-arrow-right"></i></a></div>
    </div>
    <div class="row">
        <div class="col-md-12 text-md-center text-center"> 
            <p style="font-weight:400;background-color:#343a40;width:100%;height:fit-content;color:white;padding:10px">&copy; 2024 MachineLearningMath. All rights reserved.</p>
        </div>
    </div>
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.9.2/dist/umd/popper.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
</body>
</html>
